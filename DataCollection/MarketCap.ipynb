{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.common.exceptions import NoSuchElementException,ElementClickInterceptedException,StaleElementReferenceException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from bs4 import BeautifulSoup\n",
    "import re,os,requests\n",
    "import subprocess\n",
    "import financedatabase as fd\n",
    "from io import StringIO\n",
    "import threading\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting tickers and meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "equities = fd.Equities()\n",
    "equities_united_states = equities.select(country=\"United States\")\n",
    "df = equities_united_states.query('market_cap.isin([\"Mega Cap\",\"Large Cap\",\"Mid Cap\",\"Small Cap\",\"Micro Cap\"])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Health Care', 'Materials', 'Financials', 'Industrials',\n",
       "       'Consumer Staples', 'Real Estate', nan, 'Consumer Discretionary',\n",
       "       'Information Technology', 'Communication Services', 'Energy',\n",
       "       'Utilities'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equities_united_states['sector'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector='Communication Services'\n",
    "tickers=list(equities_united_states.query(f\"sector=='{sector}'\").index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium_stealth import stealth\n",
    "\n",
    "\n",
    "\n",
    "class Browser:\n",
    "    def __init__(self, options:str ,open_on: str = '',undetected: bool =False):\n",
    "        print('Launching Browser.')\n",
    "        self.browser = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "        if open_on:\n",
    "            self.open_page(url=open_on)\n",
    "    \n",
    "    def open_page(self, url: str):\n",
    "        print(f\"Opening {url}.\")\n",
    "        self.browser.get(url)\n",
    "\n",
    "    def close_browser(self):\n",
    "        print('Closing Browser.')\n",
    "        self.browser.close()\n",
    "        \n",
    "    def click_button(self, by: By, value: str):\n",
    "        tries=0\n",
    "        while tries<100:\n",
    "            try:\n",
    "                button = self.browser.find_element(by=by, value=value)\n",
    "                button.click()\n",
    "                time.sleep(0.5)\n",
    "                break\n",
    "            except NoSuchElementException as e:\n",
    "                tries+=1\n",
    "                print(f'retrying {tries}')\n",
    "                    \n",
    "        else:\n",
    "            raise e\n",
    "    def download_csv(self):\n",
    "        button_xpath='//*[@id=\"main\"]/div[2]/div[1]/div[3]/div[1]/div/div[2]'\n",
    "        download_xpath='//*[@id=\"main\"]/div[2]/div[1]/div[3]/div[1]/div/div[2]/div/button[4]'\n",
    "        self.click_button(by=By.XPATH,value=button_xpath)\n",
    "        self.click_button(by=By.XPATH,value=download_xpath)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FetchTable(browser):\n",
    "    \n",
    "    def element_exists_by_xpath(xpath):\n",
    "        try:\n",
    "            browser.browser.find_element(by=By.XPATH,value=xpath)\n",
    "        except NoSuchElementException:\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def fetch_by_xpath(xpath):\n",
    "        try:\n",
    "            txt=browser.browser.find_element(by=By.XPATH,value=xpath).text\n",
    "        except StaleElementReferenceException:\n",
    "            time.sleep(0.1)\n",
    "            txt=browser.browser.find_element(by=By.XPATH,value=xpath).text\n",
    "            \n",
    "        if isinstance(txt,str):\n",
    "            txt=re.sub(r'(?<= \\d{4}) ',\";\",txt.replace('Date Value\\n',''))\n",
    "        return txt\n",
    "    \n",
    "    Table=''\n",
    "    tries=0\n",
    "    pages=30\n",
    "    next_button_xpath= f'//*[@id=\"ycn-historical-data-table-0\"]/div[2]/div/div[7]'\n",
    "    data_xpath='//*[@id=\"ycn-historical-data-table-0\"]/div[3]/div'\n",
    "    page_number_xpath = f'//*[@id=\"ycn-historical-data-table-0\"]/div[2]/div/div[1]'\n",
    "    while tries<10:\n",
    "        try:\n",
    "            pages=int(re.search(r'\\d*$',browser.browser.find_element(by=By.XPATH,value=page_number_xpath).text)[0])+1\n",
    "            break\n",
    "        except Exception:\n",
    "            tries+=1\n",
    "\n",
    "    for page in range(1,pages):\n",
    "        print('fetshing data on page '+str(page)+f\" out of {pages-1}\")\n",
    "        if element_exists_by_xpath(data_xpath):\n",
    "            txt_page=fetch_by_xpath(data_xpath)\n",
    "            while (txt_page in Table):\n",
    "                time.sleep(1)\n",
    "                txt_page=fetch_by_xpath(data_xpath)\n",
    "                \n",
    "            Table=f\"{Table}{txt_page}\\n\"\n",
    "            print(len(Table))    \n",
    "            # if txt_page not in Table:\n",
    "            #     Table=f\"{Table}{txt_page}\\n\"\n",
    "            #     print(\"copied\")\n",
    "            try:\n",
    "                browser.click_button(by=By.XPATH,value=next_button_xpath)\n",
    "                print('Clickable and clicked')\n",
    "            except ElementClickInterceptedException:\n",
    "                if txt_page not in Table:\n",
    "                    Table=f\"{Table}{txt_page}\\n\"\n",
    "    return Table.replace('Date Value\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_Ycharts(browser,ticker):\n",
    "    browser.open_page(url=f\"https://ycharts.com/companies/{ticker}/market_cap\")\n",
    "    time.sleep(0.2)\n",
    "    if 'Page Not Found' in browser.browser.page_source:\n",
    "        print('No Data found for'+ticker)\n",
    "        return False\n",
    "    if  \"Market Cap\" not in browser.browser.find_element(by=By.XPATH,value=f'/html/body/main/div/div[3]/div/div/div/div[1]/div/h1').text:\n",
    "        return False\n",
    "    Table=FetchTable(browser)\n",
    "    if not Table:\n",
    "        return False\n",
    "    df=pd.DataFrame(list(map(lambda x: x.split(';'),Table.split('\\n'))),columns = ['Date', 'Market Cap']).set_index('Date').dropna().applymap(lambda x: float(x[:-1])*10**12 if x.endswith(\"T\") else float(x[:-1])*10**9 if x.endswith(\"B\") else float(x[:-1])*10**6  if x.endswith(\"M\") else float(x[:-1])*10**3 )\n",
    "    df.index=pd.to_datetime(df.index)\n",
    "    df.to_csv(fr'Data\\Stockanalysis.com\\{ticker}-market-cap.csv')\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the path to the Data folder\n",
    "def list_done():\n",
    "    data_folder_path = f'Data\\Stockanalysis.com\\{sector}\\Stocks'\n",
    "\n",
    "# Create an empty list to hold the tickers\n",
    "    Done = []\n",
    "\n",
    "# Loop through all the files in the Data folder\n",
    "    for filename in os.listdir(data_folder_path):\n",
    "    # Check if the file is a CSV file\n",
    "        if filename.endswith('.csv') and ('-' in filename):\n",
    "        # Get the ticker from the filename\n",
    "            ticker = filename.split('-')[0].upper()\n",
    "        \n",
    "        # Add the ticker to the list\n",
    "            Done.append(ticker)\n",
    "    return Done\n",
    "\n",
    "Done=list_done()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "skiped=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ychart_tickers=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def first_process(browser,Ychart_tickers,skiped):\n",
    "    Tickers_to_fetch = list(set(tickers)-set(list_done())-set(skiped))\n",
    "    for k,ticker in enumerate(Tickers_to_fetch):\n",
    "        button_xpath='//*[@id=\"main\"]/div[2]/div[1]/div[4]/div/div[1]/div[2]/div[2]/button'\n",
    "        download_xpath='//*[@id=\"main\"]/div[2]/div[1]/div[4]/div/div[1]/div[2]/div[2]/div/button[2]'\n",
    "        check_tries=0\n",
    "        browser.open_page(f\"https://stockanalysis.com/stocks/{ticker}/market-cap/\")\n",
    "        time.sleep(0.5)\n",
    "        while ('Just a moment...' in browser.browser.page_source) and check_tries<3000:\n",
    "            browser.open_page(f\"https://stockanalysis.com/stocks/{ticker}/market-cap/\")\n",
    "            check_tries+=1\n",
    "            time.sleep(5*check_tries)\n",
    "            browser.browser.execute_script(f'''window.open(\"https://stockanalysis.com/stocks/{ticker}/market-cap/\",\"_blank\");''')\n",
    "            browser.browser.close()\n",
    "            browser.browser.switch_to.window(window_name=browser.browser.window_handles[-1])\n",
    "        if (not 'Page Not Found - 404' in browser.browser.page_source) and (not \"No market cap history was found for this stock.\" in browser.browser.page_source):\n",
    "            # try:\n",
    "                browser.click_button(by=By.XPATH,value=button_xpath)\n",
    "                time.sleep(0.1)\n",
    "                browser.click_button(by=By.XPATH,value=download_xpath)\n",
    "                time.sleep(0.1)\n",
    "            # except Exception:\n",
    "            #     skiped.append(ticker)\n",
    "        else:\n",
    "            if ticker not in Ychart_tickers:\n",
    "                Ychart_tickers.append(ticker)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        print(f'{(k+1)/len(tickers):.2f} % done and {len(skiped)} ({len(skiped)/len(Tickers_to_fetch):.2f}%) skipped')\n",
    "    Ychart_tickers.append('Terminate Process')\n",
    "\n",
    "def second_process(browser,Ychart_tickers,skiped):\n",
    "    \n",
    "    while True:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        if Ychart_tickers:\n",
    "            for ticker in Ychart_tickers:\n",
    "                if ticker=='Terminate Process':\n",
    "                    return\n",
    "                if not check_Ycharts(browser,ticker):     \n",
    "                    skiped.append(ticker)\n",
    "                Ychart_tickers.remove(ticker)\n",
    "        else:\n",
    "            print(\"list is empty checking again\")\n",
    "            time.sleep(1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "options1 = webdriver.ChromeOptions()\n",
    "options1.add_argument(\"--user-data-dir=C:/Users/amine/AppData/Local/Google/Chrome/User Data/Profile 2/\")\n",
    "options2 = webdriver.ChromeOptions()\n",
    "options2.add_argument(\"--user-data-dir=C:/Users/amine/AppData/Local/Google/Chrome/User Data/Profile 3/\")\n",
    "options3 = webdriver.ChromeOptions()\n",
    "options3.add_argument(\"--user-data-dir=C:/Users/amine/AppData/Local/Google/Chrome/User Data/Profile 4/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching Browser.\n"
     ]
    }
   ],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--user-data-dir=C:/Users/amine/AppData/Local/Google/Chrome/User Data/Profile 1/\")\n",
    "\n",
    "browser = Browser(options)\n",
    "# browser1 = Browser(options1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening https://ycharts.com/companies/ADVWW/market_cap.\n",
      "No Data found forADVWW\n"
     ]
    }
   ],
   "source": [
    "# t1 = threading.Thread(target=first_process, args=(browser,Ychart_tickers,skiped))\n",
    "t2 = threading.Thread(target=second_process, args=(browser1,Ychart_tickers,skiped))\n",
    "\n",
    "# starting thread 1\n",
    "# t1.start()\n",
    "# starting thread 2\n",
    "t2.start()\n",
    "\n",
    "# wait until thread 1 is completely executed\n",
    "# t1.join()\n",
    "# wait until thread 2 is completely executed\n",
    "t2.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Terminate Process']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ychart_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScrapeThread(threading.Thread):\n",
    "    def __init__(self,List_Tickers,Results,options,skiped=[]):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.Results=Results\n",
    "        self.options = options\n",
    "        self.List_Tickers = List_Tickers\n",
    "        self.skiped=skiped\n",
    "    \n",
    "    def run(self):\n",
    "        self.browser = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=self.options)\n",
    "        try:\n",
    "            self.SCRAPPING(self.List_Tickers)\n",
    "        except BaseException as e:\n",
    "            self.exc = e\n",
    "        # time.wait()\n",
    "    def join(self, timeout=None):\n",
    "        super(ScrapeThread, self).join(timeout)\n",
    "        if self.exc:\n",
    "            raise self.exc\n",
    "        return self.ret\n",
    "    \n",
    "    def open_page(self, url: str,new_tab=False):\n",
    "        \n",
    "        print(f\"Opening {url}.\")\n",
    "        if new_tab:\n",
    "            self.browser.execute_script(f'''window.open(\"{url}\",\"_blank\");''')\n",
    "        else:\n",
    "            self.browser.get(url)\n",
    "  \n",
    "    def click_button(self, by: By, value: str):\n",
    "        button = self.browser.find_element(by=by, value=value)\n",
    "        button.click()\n",
    "    \n",
    "    def is_clickable(self, by: By, value: str):\n",
    "        try:\n",
    "            # Wait up to 10 seconds for the element to be clickable\n",
    "            element = WebDriverWait(self.browser, 5).until(EC.element_to_be_clickable((by, value)))\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    def SCRAPPING(self,Tickers):\n",
    "        MC={}\n",
    "        if Tickers is None:\n",
    "            Tickers=equities_united_states.query(\"sector=='Utilities'\").index\n",
    "        Tickers=list(set(Tickers)- set(self.Results.keys())-set(self.skiped))\n",
    "        new_window=False\n",
    "        # self.browser.switch_to.window(window_name=self.browser.window_handles[-1])\n",
    "        # if new_window:\n",
    "        #     self.browser.switch_to.new_window('window')\n",
    "        if isinstance(Tickers,str):\n",
    "            Tickers=[Tickers]\n",
    "        for i,ticker in enumerate(Tickers):\n",
    "            self.open_page(url=f\"https://ycharts.com/companies/{ticker}/market_cap\")\n",
    "\n",
    "            if 'Page Not Found' in self.browser.page_source:\n",
    "                print('No Data found for'+ticker)\n",
    "                self.skiped.append(ticker)\n",
    "                continue\n",
    "            if  \"Market Cap\" not in self.browser.find_element(by=By.XPATH,value=f'/html/body/main/div/div[3]/div/div/div/div[1]/div/h1').text:\n",
    "                self.skiped.append(ticker)\n",
    "                continue\n",
    "            Table=self.FetchTable()\n",
    "            if not Table:\n",
    "                self.skiped.append(ticker)\n",
    "                continue\n",
    "            MC[ticker]=pd.DataFrame(list(map(lambda x: x.split(';'),Table.split('\\n'))),columns = ['Date', 'Market Cap']).set_index('Date').dropna().applymap(lambda x: float(x[:-1])*10**12 if x.endswith(\"T\") else float(x[:-1])*10**9 if x.endswith(\"B\") else float(x[:-1])*10**6  if x.endswith(\"M\") else float(x[:-1])*10**3 )\n",
    "            MC[ticker].index=pd.to_datetime(MC[ticker].index)\n",
    "            MC[ticker].reset_index(inplace=True)\n",
    "            if not i%5:\n",
    "                self.Results.update(MC)\n",
    "            self.Results.update(MC)\n",
    "\n",
    "    def FetchTable(self):\n",
    "        \n",
    "        def element_exists_by_xpath(xpath):\n",
    "            try:\n",
    "                self.browser.find_element(by=By.XPATH,value=xpath)\n",
    "            except NoSuchElementException:\n",
    "                return False\n",
    "            return True\n",
    "        \n",
    "        def fetch_by_xpath(xpath):\n",
    "            try:\n",
    "                txt=self.browser.find_element(by=By.XPATH,value=xpath).text\n",
    "            except StaleElementReferenceException:\n",
    "                time.sleep(0.1)\n",
    "                txt=self.browser.find_element(by=By.XPATH,value=xpath).text\n",
    "                \n",
    "            if isinstance(txt,str):\n",
    "                txt=re.sub(r'(?<= \\d{4}) ',\";\",txt.replace('Date Value\\n',''))\n",
    "            return txt\n",
    "\n",
    "        Table=''\n",
    "        tries=0\n",
    "        pages=30\n",
    "        next_button_xpath= f'//*[@id=\"ycn-historical-data-table-0\"]/div[2]/div/div[7]'\n",
    "        data_xpath='//*[@id=\"ycn-historical-data-table-0\"]/div[3]/div'\n",
    "        page_number_xpath = f'//*[@id=\"ycn-historical-data-table-0\"]/div[2]/div/div[1]'\n",
    "        while tries<10:\n",
    "            try:\n",
    "                pages=int(re.search(r'\\d*$',self.browser.find_element(by=By.XPATH,value=page_number_xpath).text)[0])+1\n",
    "                break\n",
    "            except Exception:\n",
    "                tries+=1\n",
    "\n",
    "        for page in range(1,pages):\n",
    "            print('fetshing data on page '+str(page)+f\" out of {pages-1}\")\n",
    "            if element_exists_by_xpath(data_xpath):\n",
    "                txt_page=fetch_by_xpath(data_xpath)\n",
    "                while (txt_page in Table):\n",
    "                    time.sleep(1)\n",
    "                    txt_page=fetch_by_xpath(data_xpath)\n",
    "                    \n",
    "                Table=f\"{Table}{txt_page}\\n\"\n",
    "                print(len(Table))    \n",
    "                # if txt_page not in Table:\n",
    "                #     Table=f\"{Table}{txt_page}\\n\"\n",
    "                #     print(\"copied\")\n",
    "                try:\n",
    "                    self.click_button(by=By.XPATH,value=next_button_xpath)\n",
    "                    print('Clickable and clicked')\n",
    "                except ElementClickInterceptedException:\n",
    "                    if txt_page not in Table:\n",
    "                        Table=f\"{Table}{txt_page}\\n\"\n",
    "        return Table.replace('Date Value\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScrapeThreadv2(threading.Thread):\n",
    "    def __init__(self,List_Tickers,Results,options,skiped=[]):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.Results=Results\n",
    "        self.options = options\n",
    "        self.List_Tickers = List_Tickers\n",
    "        self.skiped=skiped\n",
    "    \n",
    "    def run(self):\n",
    "        self.browser = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=self.options)\n",
    "        try:\n",
    "            self.SCRAPPING(self.List_Tickers)\n",
    "        except BaseException as e:\n",
    "            self.exc = e\n",
    "        # time.wait()\n",
    "    def join(self, timeout=None):\n",
    "        super(ScrapeThread, self).join(timeout)\n",
    "        if self.exc:\n",
    "            raise self.exc\n",
    "        return self.ret\n",
    "    \n",
    "    def open_page(self, url: str,new_tab=False):\n",
    "        \n",
    "        print(f\"Opening {url}.\")\n",
    "        if new_tab:\n",
    "            self.browser.execute_script(f'''window.open(\"{url}\",\"_blank\");''')\n",
    "        else:\n",
    "            self.browser.get(url)\n",
    "  \n",
    "    def click_button(self, by: By, value: str):\n",
    "        button = self.browser.find_element(by=by, value=value)\n",
    "        button.click()\n",
    "    \n",
    "    def is_clickable(self, by: By, value: str):\n",
    "        try:\n",
    "            # Wait up to 10 seconds for the element to be clickable\n",
    "            element = WebDriverWait(self.browser, 5).until(EC.element_to_be_clickable((by, value)))\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    def download_csv(self):\n",
    "        button_xpath='//*[@id=\"main\"]/div[2]/div[1]/div[3]/div[1]/div/div[2]'\n",
    "        download_xpath='//*[@id=\"main\"]/div[2]/div[1]/div[3]/div[1]/div/div[2]/div/button[4]'\n",
    "        self.click_button(by=By.XPATH,value=button_xpath)\n",
    "        self.click_button(by=By.XPATH,value=download_xpath)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "Results={}\n",
    "sector='Financials'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening https://ycharts.com/companies/DIS/market_cap.\n",
      "Opening https://ycharts.com/companies/A/market_cap.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-32:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\amine\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\amine\\AppData\\Local\\Temp\\ipykernel_19708\\4100611930.py\", line 10, in run\n",
      "  File \"c:\\Users\\amine\\OneDrive\\Documents\\PFA\\.venv\\lib\\site-packages\\selenium\\webdriver\\chrome\\webdriver.py\", line 84, in __init__\n",
      "    super().__init__(\n",
      "  File \"c:\\Users\\amine\\OneDrive\\Documents\\PFA\\.venv\\lib\\site-packages\\selenium\\webdriver\\chromium\\webdriver.py\", line 104, in __init__\n",
      "    super().__init__(\n",
      "  File \"c:\\Users\\amine\\OneDrive\\Documents\\PFA\\.venv\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 286, in __init__\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening https://ycharts.com/companies/AAPL/market_cap.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    self.start_session(capabilities, browser_profile)\n",
      "  File \"c:\\Users\\amine\\OneDrive\\Documents\\PFA\\.venv\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 378, in start_session\n",
      "    response = self.execute(Command.NEW_SESSION, parameters)\n",
      "  File \"c:\\Users\\amine\\OneDrive\\Documents\\PFA\\.venv\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 440, in execute\n",
      "    self.error_handler.check_response(response)\n",
      "  File \"c:\\Users\\amine\\OneDrive\\Documents\\PFA\\.venv\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\", line 245, in check_response\n",
      "    raise exception_class(message, screen, stacktrace)\n",
      "selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: exited normally.\n",
      "  (unknown error: DevToolsActivePort file doesn't exist)\n",
      "  (The process started from chrome location C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n",
      "Stacktrace:\n",
      "Backtrace:\n",
      "\tGetHandleVerifier [0x0101DCE3+50899]\n",
      "\t(No symbol) [0x00FAE111]\n",
      "\t(No symbol) [0x00EB5588]\n",
      "\t(No symbol) [0x00ED281C]\n",
      "\t(No symbol) [0x00ECF479]\n",
      "\t(No symbol) [0x00F01FFE]\n",
      "\t(No symbol) [0x00F01CEC]\n",
      "\t(No symbol) [0x00EFB6F6]\n",
      "\t(No symbol) [0x00ED7708]\n",
      "\t(No symbol) [0x00ED886D]\n",
      "\tGetHandleVerifier [0x01283EAE+2566302]\n",
      "\tGetHandleVerifier [0x012B92B1+2784417]\n",
      "\tGetHandleVerifier [0x012B327C+2759788]\n",
      "\tGetHandleVerifier [0x010B5740+672048]\n",
      "\t(No symbol) [0x00FB8872]\n",
      "\t(No symbol) [0x00FB41C8]\n",
      "\t(No symbol) [0x00FB42AB]\n",
      "\t(No symbol) [0x00FA71B7]\n",
      "\tBaseThreadInitThunk [0x767D0099+25]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x77117B6E+286]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x77117B3E+238]\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ScrapeThread' object has no attribute 'exc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[191], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m \tthreads\u001b[39m.\u001b[39mappend(t)\n\u001b[0;32m     44\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m threads:\n\u001b[1;32m---> 45\u001b[0m \tt\u001b[39m.\u001b[39;49mjoin()\t\n\u001b[0;32m     47\u001b[0m cc_MC\u001b[39m=\u001b[39m\u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(Results\u001b[39m.\u001b[39mkeys(),\u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mset_index(\u001b[39m\"\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m\"\u001b[39m) ,Results\u001b[39m.\u001b[39mvalues()))))\n\u001b[0;32m     48\u001b[0m pd\u001b[39m.\u001b[39mconcat(cc_MC,axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto_csv(\u001b[39mfr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mData\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mScraped MarketCap\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m{\u001b[39;00msector\u001b[39m}\u001b[39;00m\u001b[39m.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[188], line 18\u001b[0m, in \u001b[0;36mScrapeThread.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mjoin\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     17\u001b[0m     \u001b[39msuper\u001b[39m(ScrapeThread, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mjoin(timeout)\n\u001b[1;32m---> 18\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexc:\n\u001b[0;32m     19\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexc\n\u001b[0;32m     20\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mret\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ScrapeThread' object has no attribute 'exc'"
     ]
    }
   ],
   "source": [
    "# %store Results\n",
    "# %store -r Results\n",
    "# %store skiped\n",
    "# %store -r skiped\n",
    "\n",
    "my_list = equities_united_states.query(f'sector==\"{sector}\"').index\n",
    "\n",
    "\n",
    "# Determine the length of each part\n",
    "part_length = len(my_list) // 4\n",
    "\n",
    "Test_tickers = [\n",
    "\t[\"TSLA\"],\n",
    "\t['A'],\n",
    "\t['AAPL'],\n",
    "\t['DIS']\n",
    "\t# my_list[:part_length],\n",
    "\t# my_list[part_length:part_length*2],\n",
    "\t# my_list[part_length*2:part_length*3],\n",
    "\t# my_list[part_length*3:]\n",
    "]\n",
    "\n",
    "\n",
    "# Options = [webdriver.ChromeOptions()]*len(Test_tickers)\n",
    "\n",
    "\n",
    "\n",
    "Options = [options,options1,options2,options3]\n",
    "\n",
    "threads = []\n",
    "for i,Tickers in enumerate(Test_tickers):\n",
    "\tt = ScrapeThread(Tickers,Results,Options[i])\n",
    "\tt.start()\n",
    "\tthreads.append(t)\n",
    "\n",
    "for t in threads:\n",
    "\tt.join()\t\n",
    " \n",
    "cc_MC=dict(zip(Results.keys(),list(map(lambda x: x.set_index(\"Date\") ,Results.values()))))\n",
    "pd.concat(cc_MC,axis=1).to_csv(fr'Data\\Scraped MarketCap\\{sector}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OSPN', 'MCAA', 'UNIB', 'MFDB', 'FITB', 'PMVC', 'SSBI', 'TOWN', 'FRBK', 'OPY']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(Results.keys())[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cc_MC=dict(zip(Results.keys(),list(map(lambda x: x.set_index(\"Date\") ,Results.values()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(cc_MC,axis=1).to_csv(fr'Data\\Scraped MarketCap\\{sector}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching Browser.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Browser at 0x18220b4b040>"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Browser(options,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching Browser.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Browser at 0x18220b1c2e0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Browser(options1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'MC' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store MC\n",
    "corrected_MC=dict(zip(MC.keys(),list(map(lambda x: x[['Date','Market Cap']],MC.values()))))\n",
    "pd.concat(MC,axis=1).to_csv('Data/Scraped MarketCap/NON-Utilities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: disconnected: not connected to DevTools\n  (failed to check if window was closed: disconnected: not connected to DevTools)\n  (Session info: chrome=112.0.5615.138)\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x0082DCE3+50899]\n\t(No symbol) [0x007BE111]\n\t(No symbol) [0x006C5588]\n\t(No symbol) [0x006B70CB]\n\t(No symbol) [0x006B778A]\n\t(No symbol) [0x006B7728]\n\t(No symbol) [0x006AC37A]\n\t(No symbol) [0x006ACBD7]\n\t(No symbol) [0x007144AB]\n\t(No symbol) [0x0070B8C3]\n\t(No symbol) [0x006E7708]\n\t(No symbol) [0x006E886D]\n\tGetHandleVerifier [0x00A93EAE+2566302]\n\tGetHandleVerifier [0x00AC92B1+2784417]\n\tGetHandleVerifier [0x00AC327C+2759788]\n\tGetHandleVerifier [0x008C5740+672048]\n\t(No symbol) [0x007C8872]\n\t(No symbol) [0x007C41C8]\n\t(No symbol) [0x007C42AB]\n\t(No symbol) [0x007B71B7]\n\tBaseThreadInitThunk [0x767D0099+25]\n\tRtlGetAppContainerNamedObjectPath [0x77117B6E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77117B3E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[105], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m Tickers\u001b[39m=\u001b[39mtickers\n\u001b[0;32m      2\u001b[0m new_window\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m browser\u001b[39m.\u001b[39mbrowser\u001b[39m.\u001b[39mswitch_to\u001b[39m.\u001b[39mwindow(window_name\u001b[39m=\u001b[39mbrowser\u001b[39m.\u001b[39;49mbrowser\u001b[39m.\u001b[39;49mwindow_handles[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[0;32m      4\u001b[0m \u001b[39mif\u001b[39;00m new_window:\n\u001b[0;32m      5\u001b[0m     browser\u001b[39m.\u001b[39mbrowser\u001b[39m.\u001b[39mswitch_to\u001b[39m.\u001b[39mnew_window(\u001b[39m'\u001b[39m\u001b[39mwindow\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\amine\\OneDrive\\Documents\\PFA\\.venv\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:587\u001b[0m, in \u001b[0;36mWebDriver.window_handles\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m    579\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwindow_handles\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mstr\u001b[39m]:\n\u001b[0;32m    580\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns the handles of all windows within the current session.\u001b[39;00m\n\u001b[0;32m    581\u001b[0m \n\u001b[0;32m    582\u001b[0m \u001b[39m    :Usage:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[39m            driver.window_handles\u001b[39;00m\n\u001b[0;32m    586\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 587\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(Command\u001b[39m.\u001b[39;49mW3C_GET_WINDOW_HANDLES)[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\amine\\OneDrive\\Documents\\PFA\\.venv\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:440\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    438\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_executor\u001b[39m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    439\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[1;32m--> 440\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_handler\u001b[39m.\u001b[39;49mcheck_response(response)\n\u001b[0;32m    441\u001b[0m     response[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unwrap_value(response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    442\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\amine\\OneDrive\\Documents\\PFA\\.venv\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:245\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    243\u001b[0m         alert_text \u001b[39m=\u001b[39m value[\u001b[39m\"\u001b[39m\u001b[39malert\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    244\u001b[0m     \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[39m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 245\u001b[0m \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: disconnected: not connected to DevTools\n  (failed to check if window was closed: disconnected: not connected to DevTools)\n  (Session info: chrome=112.0.5615.138)\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x0082DCE3+50899]\n\t(No symbol) [0x007BE111]\n\t(No symbol) [0x006C5588]\n\t(No symbol) [0x006B70CB]\n\t(No symbol) [0x006B778A]\n\t(No symbol) [0x006B7728]\n\t(No symbol) [0x006AC37A]\n\t(No symbol) [0x006ACBD7]\n\t(No symbol) [0x007144AB]\n\t(No symbol) [0x0070B8C3]\n\t(No symbol) [0x006E7708]\n\t(No symbol) [0x006E886D]\n\tGetHandleVerifier [0x00A93EAE+2566302]\n\tGetHandleVerifier [0x00AC92B1+2784417]\n\tGetHandleVerifier [0x00AC327C+2759788]\n\tGetHandleVerifier [0x008C5740+672048]\n\t(No symbol) [0x007C8872]\n\t(No symbol) [0x007C41C8]\n\t(No symbol) [0x007C42AB]\n\t(No symbol) [0x007B71B7]\n\tBaseThreadInitThunk [0x767D0099+25]\n\tRtlGetAppContainerNamedObjectPath [0x77117B6E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77117B3E+238]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Tickers=tickers\n",
    "new_window=True\n",
    "browser.browser.switch_to.window(window_name=browser.browser.window_handles[-1])\n",
    "if new_window:\n",
    "    browser.browser.switch_to.new_window('window')\n",
    "if isinstance(Tickers,str):\n",
    "    Tickers=[Tickers]\n",
    "MC={}\n",
    "for ticker in Tickers:\n",
    "    browser.open_page(url=f\"https://ycharts.com/companies/{ticker}/market_cap\")\n",
    "    \n",
    "    if 'Page Not Found' in browser.browser.page_source:\n",
    "        logs('No Data found for'+ticker)\n",
    "        end_logs()\n",
    "        continue\n",
    "    Table=browser.FetchTable()\n",
    "    if not Table:\n",
    "        continue\n",
    "    MC[ticker]=pd.DataFrame(list(map(lambda x: x.split(';'),Table.split('\\n'))),columns = ['Date', 'Market Cap']).set_index('Date').dropna().applymap(lambda x: float(x[:-1])*10**9 if x.endswith(\"B\") else float(x[:-1])*10**6  if x.endswith(\"M\") else float(x[:-1])*10**3 )\n",
    "    MC[ticker].index=pd.to_datetime(MC[ticker].index)\n",
    "Results.append(MC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'DATE'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfunctools\u001b[39;00m \u001b[39mimport\u001b[39;00m reduce\n\u001b[1;32m----> 3\u001b[0m reduce(\u001b[39mlambda\u001b[39;49;00m  left,right: pd\u001b[39m.\u001b[39;49mmerge(left,right,on\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mDATE\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m      4\u001b[0m                                             how\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mouter\u001b[39;49m\u001b[39m'\u001b[39;49m), MC\u001b[39m.\u001b[39;49mvalues())\n",
      "Cell \u001b[1;32mIn[42], line 3\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(left, right)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfunctools\u001b[39;00m \u001b[39mimport\u001b[39;00m reduce\n\u001b[1;32m----> 3\u001b[0m reduce(\u001b[39mlambda\u001b[39;00m  left,right: pd\u001b[39m.\u001b[39;49mmerge(left,right,on\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mDATE\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m      4\u001b[0m                                             how\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mouter\u001b[39;49m\u001b[39m'\u001b[39;49m), MC\u001b[39m.\u001b[39mvalues())\n",
      "File \u001b[1;32mc:\\Users\\amine\\OneDrive\\Documents\\PFA\\.venv\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:110\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mleft : DataFrame or named Series\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     94\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    109\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m--> 110\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[0;32m    111\u001b[0m         left,\n\u001b[0;32m    112\u001b[0m         right,\n\u001b[0;32m    113\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[0;32m    114\u001b[0m         on\u001b[39m=\u001b[39;49mon,\n\u001b[0;32m    115\u001b[0m         left_on\u001b[39m=\u001b[39;49mleft_on,\n\u001b[0;32m    116\u001b[0m         right_on\u001b[39m=\u001b[39;49mright_on,\n\u001b[0;32m    117\u001b[0m         left_index\u001b[39m=\u001b[39;49mleft_index,\n\u001b[0;32m    118\u001b[0m         right_index\u001b[39m=\u001b[39;49mright_index,\n\u001b[0;32m    119\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    120\u001b[0m         suffixes\u001b[39m=\u001b[39;49msuffixes,\n\u001b[0;32m    121\u001b[0m         indicator\u001b[39m=\u001b[39;49mindicator,\n\u001b[0;32m    122\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[0;32m    123\u001b[0m     )\n\u001b[0;32m    124\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result(copy\u001b[39m=\u001b[39mcopy)\n",
      "File \u001b[1;32mc:\\Users\\amine\\OneDrive\\Documents\\PFA\\.venv\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:703\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cross \u001b[39m=\u001b[39m cross_col\n\u001b[0;32m    698\u001b[0m \u001b[39m# note this function has side effects\u001b[39;00m\n\u001b[0;32m    699\u001b[0m (\n\u001b[0;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft_join_keys,\n\u001b[0;32m    701\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright_join_keys,\n\u001b[0;32m    702\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjoin_names,\n\u001b[1;32m--> 703\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_merge_keys()\n\u001b[0;32m    705\u001b[0m \u001b[39m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[0;32m    706\u001b[0m \u001b[39m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[0;32m    707\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_coerce_merge_keys()\n",
      "File \u001b[1;32mc:\\Users\\amine\\OneDrive\\Documents\\PFA\\.venv\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1162\u001b[0m, in \u001b[0;36m_MergeOperation._get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1160\u001b[0m rk \u001b[39m=\u001b[39m cast(Hashable, rk)\n\u001b[0;32m   1161\u001b[0m \u001b[39mif\u001b[39;00m rk \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1162\u001b[0m     right_keys\u001b[39m.\u001b[39mappend(right\u001b[39m.\u001b[39;49m_get_label_or_level_values(rk))\n\u001b[0;32m   1163\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1164\u001b[0m     \u001b[39m# work-around for merge_asof(right_index=True)\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m     right_keys\u001b[39m.\u001b[39mappend(right\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\amine\\OneDrive\\Documents\\PFA\\.venv\\lib\\site-packages\\pandas\\core\\generic.py:1850\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1844\u001b[0m     values \u001b[39m=\u001b[39m (\n\u001b[0;32m   1845\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis]\n\u001b[0;32m   1846\u001b[0m         \u001b[39m.\u001b[39mget_level_values(key)  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m   1847\u001b[0m         \u001b[39m.\u001b[39m_values\n\u001b[0;32m   1848\u001b[0m     )\n\u001b[0;32m   1849\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1850\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n\u001b[0;32m   1852\u001b[0m \u001b[39m# Check for duplicates\u001b[39;00m\n\u001b[0;32m   1853\u001b[0m \u001b[39mif\u001b[39;00m values\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'DATE'"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "reduce(lambda  left,right: pd.merge(left,right,on=['DATE'],\n",
    "                                            how='outer'), MC.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.browser.find_element(By.TAG_NAME ,'body').send_keys(Keys.COMMAND + 't') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_name = browser.browser.window_handles[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.browser.switch_to.window(window_name=window_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.open_page(url=f\"https://ycharts.com/companies/{ticker}/market_cap\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
